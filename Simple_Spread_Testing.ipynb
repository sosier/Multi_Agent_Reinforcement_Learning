{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Spread Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Simple Spread (Collaborative Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent observations: `[self_vel, self_pos, landmark_rel_positions, other_agent_rel_positions, communication]`\n",
    " - `self_vel = (2, )`\n",
    " - `self_pos = (2, )`\n",
    " - `landmark_rel_positions = (2 * N, )`\n",
    " - `other_agent_rel_positions = (2 * (N - 1), )`\n",
    " - `communication = (2 * (N - 1), )`\n",
    "\n",
    "Agent action space: `[no_action, move_left, move_right, move_down, move_up] = (0-4)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.mpe import simple_spread_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_0': array([ 0.        ,  0.        ,  0.6048849 , -0.28739527, -1.4096578 ,\n",
       "          0.270138  , -0.55914074,  1.2643002 , -1.3505151 ,  0.00312318,\n",
       "         -0.73575705, -0.6072447 , -0.21943055, -0.1808943 ,  0.06576544,\n",
       "          0.04157067, -0.6578076 ,  0.33087328, -0.9477666 ,  0.3502272 ,\n",
       "         -0.04701285, -0.21415704,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_1': array([ 0.        ,  0.        ,  0.67065036, -0.24582459, -1.4754233 ,\n",
       "          0.22856732, -0.6249062 ,  1.2227296 , -1.4162806 , -0.0384475 ,\n",
       "         -0.8015225 , -0.64881533, -0.285196  , -0.22246498, -0.06576544,\n",
       "         -0.04157067, -0.723573  ,  0.2893026 , -1.013532  ,  0.3086565 ,\n",
       "         -0.11277829, -0.2557277 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_2': array([ 0.        ,  0.        , -0.05292263,  0.04347802, -0.7518503 ,\n",
       "         -0.06073529,  0.09866682,  0.9334269 , -0.6927076 , -0.3277501 ,\n",
       "         -0.07794946, -0.938118  ,  0.43837702, -0.51176757,  0.6578076 ,\n",
       "         -0.33087328,  0.723573  , -0.2893026 , -0.289959  ,  0.01935392,\n",
       "          0.6107947 , -0.5450303 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_3': array([ 0.        ,  0.        , -0.34288165,  0.06283194, -0.46189126,\n",
       "         -0.08008921,  0.38862583,  0.914073  , -0.40274858, -0.347104  ,\n",
       "          0.21200955, -0.9574719 ,  0.72833604, -0.5311215 ,  0.9477666 ,\n",
       "         -0.3502272 ,  1.013532  , -0.3086565 ,  0.289959  , -0.01935392,\n",
       "          0.90075374, -0.5643842 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_4': array([ 0.        ,  0.        ,  0.5578721 , -0.5015523 , -1.362645  ,\n",
       "          0.48429504, -0.51212794,  1.4784572 , -1.3035023 ,  0.21728022,\n",
       "         -0.6887442 , -0.39308763, -0.17241772,  0.03326274,  0.04701285,\n",
       "          0.21415704,  0.11277829,  0.2557277 , -0.6107947 ,  0.5450303 ,\n",
       "         -0.90075374,  0.5643842 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32)},\n",
       " {'agent_0': {}, 'agent_1': {}, 'agent_2': {}, 'agent_3': {}, 'agent_4': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = simple_spread_v3.parallel_env(N=5)\n",
    "observations, infos = env.reset()\n",
    "observations, infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.num_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.6048849 , -0.28739527, -1.4096578 ,\n",
       "        0.270138  , -0.55914074,  1.2643002 , -1.3505151 ,  0.00312318,\n",
       "       -0.73575705, -0.6072447 , -0.21943055, -0.1808943 ,  0.06576544,\n",
       "        0.04157067, -0.6578076 ,  0.33087328, -0.9477666 ,  0.3502272 ,\n",
       "       -0.04701285, -0.21415704,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.67065036, -0.24582459, -1.4754233 ,\n",
       "        0.22856732, -0.6249062 ,  1.2227296 , -1.4162806 , -0.0384475 ,\n",
       "       -0.8015225 , -0.64881533, -0.285196  , -0.22246498, -0.06576544,\n",
       "       -0.04157067, -0.723573  ,  0.2893026 , -1.013532  ,  0.3086565 ,\n",
       "       -0.11277829, -0.2557277 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.05292263,  0.04347802, -0.7518503 ,\n",
       "       -0.06073529,  0.09866682,  0.9334269 , -0.6927076 , -0.3277501 ,\n",
       "       -0.07794946, -0.938118  ,  0.43837702, -0.51176757,  0.6578076 ,\n",
       "       -0.33087328,  0.723573  , -0.2893026 , -0.289959  ,  0.01935392,\n",
       "        0.6107947 , -0.5450303 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.34288165,  0.06283194, -0.46189126,\n",
       "       -0.08008921,  0.38862583,  0.914073  , -0.40274858, -0.347104  ,\n",
       "        0.21200955, -0.9574719 ,  0.72833604, -0.5311215 ,  0.9477666 ,\n",
       "       -0.3502272 ,  1.013532  , -0.3086565 ,  0.289959  , -0.01935392,\n",
       "        0.90075374, -0.5643842 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.5578721 , -0.5015523 , -1.362645  ,\n",
       "        0.48429504, -0.51212794,  1.4784572 , -1.3035023 ,  0.21728022,\n",
       "       -0.6887442 , -0.39308763, -0.17241772,  0.03326274,  0.04701285,\n",
       "        0.21415704,  0.11277829,  0.2557277 , -0.6107947 ,  0.5450303 ,\n",
       "       -0.90075374,  0.5643842 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.6048849 , -0.28739527, -1.4096578 ,\n",
       "        0.270138  , -0.55914074,  1.2643002 , -1.3505151 ,  0.00312318,\n",
       "       -0.73575705, -0.6072447 , -0.21943055, -0.1808943 ,  0.06576544,\n",
       "        0.04157067, -0.6578076 ,  0.33087328, -0.9477666 ,  0.3502272 ,\n",
       "       -0.04701285, -0.21415704,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(observations[\"agent_0\"].shape)\n",
    "observations[\"agent_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space(\"agent_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_0': array([-1.7050802 , -0.3985713 ,  0.6048849 , -0.28739527, -1.4096578 ,\n",
       "          0.270138  , -0.55914074,  1.2643002 , -1.3505151 ,  0.00312318,\n",
       "         -0.73575705, -0.6072447 , -0.21943055, -0.1808943 ,  0.06576544,\n",
       "          0.04157067, -0.6578076 ,  0.33087328, -0.9477666 ,  0.3502272 ,\n",
       "         -0.04701285, -0.21415704,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_1': array([ 1.9609631 ,  1.3748716 ,  0.67065036, -0.24582459, -1.4754233 ,\n",
       "          0.22856732, -0.6249062 ,  1.2227296 , -1.4162806 , -0.0384475 ,\n",
       "         -0.8015225 , -0.64881533, -0.285196  , -0.22246498, -0.06576544,\n",
       "         -0.04157067, -0.723573  ,  0.2893026 , -1.013532  ,  0.3086565 ,\n",
       "         -0.11277829, -0.2557277 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_2': array([ 0.09375016, -0.00625755, -0.05292263,  0.04347802, -0.7518503 ,\n",
       "         -0.06073529,  0.09866682,  0.9334269 , -0.6927076 , -0.3277501 ,\n",
       "         -0.07794946, -0.938118  ,  0.43837702, -0.51176757,  0.6578076 ,\n",
       "         -0.33087328,  0.723573  , -0.2893026 , -0.289959  ,  0.01935392,\n",
       "          0.6107947 , -0.5450303 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_3': array([-0.09375016,  0.00625755, -0.34288165,  0.06283194, -0.46189126,\n",
       "         -0.08008921,  0.38862583,  0.914073  , -0.40274858, -0.347104  ,\n",
       "          0.21200955, -0.9574719 ,  0.72833604, -0.5311215 ,  0.9477666 ,\n",
       "         -0.3502272 ,  1.013532  , -0.3086565 ,  0.289959  , -0.01935392,\n",
       "          0.90075374, -0.5643842 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32),\n",
       "  'agent_4': array([-0.25588298, -0.9763003 ,  0.5578721 , -0.5015523 , -1.362645  ,\n",
       "          0.48429504, -0.51212794,  1.4784572 , -1.3035023 ,  0.21728022,\n",
       "         -0.6887442 , -0.39308763, -0.17241772,  0.03326274,  0.04701285,\n",
       "          0.21415704,  0.11277829,  0.2557277 , -0.6107947 ,  0.5450303 ,\n",
       "         -0.90075374,  0.5643842 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        dtype=float32)},\n",
       " defaultdict(int,\n",
       "             {'agent_0': -2.453857408501661,\n",
       "              'agent_1': -2.453857408501661,\n",
       "              'agent_2': -1.9538574085016613,\n",
       "              'agent_3': -1.9538574085016613,\n",
       "              'agent_4': -2.453857408501661}),\n",
       " {'agent_0': False,\n",
       "  'agent_1': False,\n",
       "  'agent_2': False,\n",
       "  'agent_3': False,\n",
       "  'agent_4': False},\n",
       " {'agent_0': False,\n",
       "  'agent_1': False,\n",
       "  'agent_2': False,\n",
       "  'agent_3': False,\n",
       "  'agent_4': False},\n",
       " {'agent_0': {}, 'agent_1': {}, 'agent_2': {}, 'agent_3': {}, 'agent_4': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is where you would insert your policy\n",
    "# actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "actions = {agent: 0 for agent in env.agents}\n",
    "observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "observations, rewards, terminations, truncations, infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Variant (Custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent observations: `[self_is_adversary, self_vel, self_pos, landmark_rel_positions, other_agent_is_adversary_rel_positions]`\n",
    " - `self_is_adversary = (1, )`: 0 / 1 flag\n",
    " - `self_vel = (2, )`\n",
    " - `self_pos = (2, )`\n",
    " - `landmark_rel_positions = (2 * n_landmarks, )`\n",
    " - `other_agent_is_adversary_rel_positions = ((1 + 2) * (n_agents + n_adversaries - 1), )`: 0 / 1 flag  for if that other agent is an adversary + relative position for the other agent times the number of other agents\n",
    "\n",
    "Agent action space: `[no_action, move_left, move_right, move_down, move_up] = (0-4)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import simple_spread_adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'adversary_0': array([ 1.        ,  0.        ,  0.        ,  0.71991843,  0.26426274,\n",
       "         -0.1886216 ,  0.1167082 ,  0.03999711,  0.66545284,  1.        ,\n",
       "         -1.709574  , -0.96413887,  0.        , -1.6893606 , -0.29679307,\n",
       "          0.        , -0.70062536, -0.05053777], dtype=float32),\n",
       "  'adversary_1': array([ 1.        ,  0.        ,  0.        , -0.98965555, -0.6998761 ,\n",
       "          1.5209525 ,  1.080847  ,  1.7495711 ,  1.6295917 ,  1.        ,\n",
       "          1.709574  ,  0.96413887,  0.        ,  0.02021344,  0.66734576,\n",
       "          0.        ,  1.0089487 ,  0.9136011 ], dtype=float32),\n",
       "  'agent_0': array([ 0.        ,  0.        ,  0.        , -0.9694421 , -0.03253032,\n",
       "          1.500739  ,  0.41350126,  1.7293577 ,  0.96224594,  1.        ,\n",
       "          1.6893606 ,  0.29679307,  1.        , -0.02021344, -0.66734576,\n",
       "          0.        ,  0.9887352 ,  0.2462553 ], dtype=float32),\n",
       "  'agent_1': array([ 0.        ,  0.        ,  0.        ,  0.01929311,  0.21372497,\n",
       "          0.5120037 ,  0.16724597,  0.74062246,  0.7159906 ,  1.        ,\n",
       "          0.70062536,  0.05053777,  1.        , -1.0089487 , -0.9136011 ,\n",
       "          0.        , -0.9887352 , -0.2462553 ], dtype=float32)},\n",
       " {'adversary_0': {}, 'adversary_1': {}, 'agent_0': {}, 'agent_1': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = simple_spread_adversarial.parallel_env(n_agents=2, n_adversaries=2, n_landmarks=2)\n",
    "observations, infos = env.reset()\n",
    "observations, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, ['adversary_0', 'adversary_1', 'agent_0', 'agent_1'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.num_agents, env.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.        ,  0.        ,  0.71991843,  0.26426274,\n",
       "       -0.1886216 ,  0.1167082 ,  0.03999711,  0.66545284,  1.        ,\n",
       "       -1.709574  , -0.96413887,  0.        , -1.6893606 , -0.29679307,\n",
       "        0.        , -0.70062536, -0.05053777,  1.        ,  0.        ,\n",
       "        0.        , -0.98965555, -0.6998761 ,  1.5209525 ,  1.080847  ,\n",
       "        1.7495711 ,  1.6295917 ,  1.        ,  1.709574  ,  0.96413887,\n",
       "        0.        ,  0.02021344,  0.66734576,  0.        ,  1.0089487 ,\n",
       "        0.9136011 ,  0.        ,  0.        ,  0.        , -0.9694421 ,\n",
       "       -0.03253032,  1.500739  ,  0.41350126,  1.7293577 ,  0.96224594,\n",
       "        1.        ,  1.6893606 ,  0.29679307,  1.        , -0.02021344,\n",
       "       -0.66734576,  0.        ,  0.9887352 ,  0.2462553 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01929311,  0.21372497,  0.5120037 ,\n",
       "        0.16724597,  0.74062246,  0.7159906 ,  1.        ,  0.70062536,\n",
       "        0.05053777,  1.        , -1.0089487 , -0.9136011 ,  0.        ,\n",
       "       -0.9887352 , -0.2462553 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.9694421 , -0.03253032,\n",
       "        1.500739  ,  0.41350126,  1.7293577 ,  0.96224594,  1.        ,\n",
       "        1.6893606 ,  0.29679307,  1.        , -0.02021344, -0.66734576,\n",
       "        0.        ,  0.9887352 ,  0.2462553 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(observations[\"agent_0\"].shape)\n",
    "observations[\"agent_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space(\"agent_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'adversary_0': array([ 1.        , -0.5       ,  0.        ,  0.71991843,  0.26426274,\n",
       "         -0.1886216 ,  0.1167082 ,  0.03999711,  0.66545284,  1.        ,\n",
       "         -1.709574  , -0.96413887,  0.        , -1.6893606 , -0.29679307,\n",
       "          0.        , -0.70062536, -0.05053777], dtype=float32),\n",
       "  'adversary_1': array([ 1.        ,  0.5       , -0.        , -0.98965555, -0.6998761 ,\n",
       "          1.5209525 ,  1.080847  ,  1.7495711 ,  1.6295917 ,  1.        ,\n",
       "          1.709574  ,  0.96413887,  0.        ,  0.02021344,  0.66734576,\n",
       "          0.        ,  1.0089487 ,  0.9136011 ], dtype=float32),\n",
       "  'agent_0': array([ 0.        , -0.5       ,  0.        , -0.9694421 , -0.03253032,\n",
       "          1.500739  ,  0.41350126,  1.7293577 ,  0.96224594,  1.        ,\n",
       "          1.6893606 ,  0.29679307,  1.        , -0.02021344, -0.66734576,\n",
       "          0.        ,  0.9887352 ,  0.2462553 ], dtype=float32),\n",
       "  'agent_1': array([ 0.        ,  0.5       , -0.        ,  0.01929311,  0.21372497,\n",
       "          0.5120037 ,  0.16724597,  0.74062246,  0.7159906 ,  1.        ,\n",
       "          0.70062536,  0.05053777,  1.        , -1.0089487 , -0.9136011 ,\n",
       "          0.        , -0.9887352 , -0.2462553 ], dtype=float32)},\n",
       " defaultdict(int,\n",
       "             {'adversary_0': 0.0,\n",
       "              'adversary_1': 0.0,\n",
       "              'agent_0': -1.5687552372783928,\n",
       "              'agent_1': -1.5687552372783928}),\n",
       " {'adversary_0': False,\n",
       "  'adversary_1': False,\n",
       "  'agent_0': False,\n",
       "  'agent_1': False},\n",
       " {'adversary_0': False,\n",
       "  'adversary_1': False,\n",
       "  'agent_0': False,\n",
       "  'agent_1': False},\n",
       " {'adversary_0': {}, 'adversary_1': {}, 'agent_0': {}, 'agent_1': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is where you would insert your policy\n",
    "# actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "observations, rewards, terminations, truncations, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize full episode\n",
    "env = simple_spread_adversarial.parallel_env(\n",
    "    n_agents=2,\n",
    "    n_adversaries=2,\n",
    "    n_landmarks=3,\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "observations, infos = env.reset()\n",
    "\n",
    "while env.agents:\n",
    "    # this is where you would insert your policy\n",
    "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_0': array([ 0.        ,  0.        , -0.38328615,  0.86822903,  0.80571675,\n",
       "         -0.17507046, -0.04091149, -0.4079286 ,  0.2609769 , -1.1527708 ,\n",
       "          0.8894034 , -1.8245099 ,  1.0836629 , -0.5118992 ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ], dtype=float32),\n",
       "  'agent_1': array([ 0.        ,  0.        ,  0.5061172 , -0.9562809 , -0.08368663,\n",
       "          1.6494395 , -0.9303149 ,  1.4165813 , -0.6284265 ,  0.67173916,\n",
       "         -0.8894034 ,  1.8245099 ,  0.19425943,  1.3126107 ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ], dtype=float32),\n",
       "  'agent_2': array([ 0.        ,  0.        ,  0.7003767 ,  0.3563299 , -0.27794608,\n",
       "          0.33682868, -1.1245743 ,  0.10397057, -0.8226859 , -0.6408716 ,\n",
       "         -1.0836629 ,  0.5118992 , -0.19425943, -1.3126107 ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ], dtype=float32)},\n",
       " {'agent_0': {}, 'agent_1': {}, 'agent_2': {}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 3\n",
    "env = simple_spread_v3.parallel_env(N=temp)\n",
    "observations, infos = env.reset()\n",
    "observations, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self vel:  [0. 0.]\n",
      "self pos:  [-0.38328615  0.86822903]\n",
      "landmarks:  [ 0.80571675 -0.17507046 -0.04091149 -0.4079286   0.2609769  -1.1527708 ]\n",
      "other players:  [ 0.8894034 -1.8245099  1.0836629 -0.5118992]\n",
      "comms:  [0. 0. 0. 0.]\n",
      "\n",
      "self vel:  [0. 0.]\n",
      "self pos:  [ 0.5061172 -0.9562809]\n",
      "landmarks:  [-0.08368663  1.6494395  -0.9303149   1.4165813  -0.6284265   0.67173916]\n",
      "other players:  [-0.8894034   1.8245099   0.19425943  1.3126107 ]\n",
      "comms:  [0. 0. 0. 0.]\n",
      "\n",
      "self vel:  [0. 0.]\n",
      "self pos:  [0.7003767 0.3563299]\n",
      "landmarks:  [-0.27794608  0.33682868 -1.1245743   0.10397057 -0.8226859  -0.6408716 ]\n",
      "other players:  [-1.0836629   0.5118992  -0.19425943 -1.3126107 ]\n",
      "comms:  [0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    observation = observations[agent]\n",
    "    \n",
    "    self_vel = observation[:2]\n",
    "    self_pos = observation[2:4]\n",
    "    idx = 4 + temp * 2\n",
    "    landmark = observation[4:idx]\n",
    "    idx2 = idx + (temp - 1) * 2\n",
    "    other_pos = observation[idx:idx2]\n",
    "    comms = observation[idx2:]\n",
    "    \n",
    "    print(\"self vel: \", self_vel)\n",
    "    print(\"self pos: \", self_pos)\n",
    "    print(\"landmarks: \", landmark)\n",
    "    print(\"other players: \", other_pos)\n",
    "    print(\"comms: \", comms)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def observation(self, agent, world):\n",
    "#         # get positions of all entities in this agent's reference frame\n",
    "#         entity_pos = []\n",
    "#         for entity in world.landmarks:  # world.entities:\n",
    "#             entity_pos.append(entity.state.p_pos - agent.state.p_pos)\n",
    "#         # communication of all other agents\n",
    "#         comm = []\n",
    "#         other_pos = []\n",
    "#         for other in world.agents:\n",
    "#             if other is agent:\n",
    "#                 continue\n",
    "#             comm.append(other.state.c)\n",
    "#             other_pos.append(other.state.p_pos - agent.state.p_pos)\n",
    "#         return np.concatenate(\n",
    "#             [agent.state.p_vel] + [agent.state.p_pos] + entity_pos + other_pos + comm\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts: Vary the amount of comm being transferred. By default, other pos are included outside of the comm vector. Potential Baselines: Mask landmarks / Mask other pos. Masking both doesn't make much sense as it essentially. becomes. Run on small number of iterations to learn policy. Ideas for custom defined comm vector: provide velocity of self to other agents (2 per other agent, 2N-1 like right now). alternatively, provide euclidan distance to each of the landmarks (my thinking is that it would explicitly force the agents to learn instead of learning implicitly via the reward func. The number would be N per agent). This could either be an absolute L2 distance or some binary variable. The binary variable could either be N per other agent (1 if within some parameter bound to landmark x, 0 if not) or 2 per other agent (1 if within some parameter bound to any landmark, 0 if not)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
